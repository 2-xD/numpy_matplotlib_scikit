{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.711226005748496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def R2_plot(y_pred, y_test):\n",
    "    print(f'R2 = {r2_score(y_test, y_pred)}')\n",
    "    plt.scatter(y_pred, y_test)\n",
    "    plt.xlabel('y_pred')\n",
    "    plt.ylabel('y_test')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "data, feature_names, target = boston['data'], boston['feature_names'], boston['target']\n",
    "\n",
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns=[\"price\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "R2_plot(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.8749965273218174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 1000, max_depth = 12, random_state = 42)\n",
    "model.fit(X_train, y_train.values[:, 0])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "R2_plot(y_pred, y_test)\n",
    "\n",
    "# Данная модель работает лучше, R^2 выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Задание 3\n",
    "\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма показателей важности: 0.9999999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.415679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>0.402705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_importance\n",
       "LSTAT         0.415679\n",
       "RM            0.402705"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Сумма показателей важности: {sum(model.feature_importances_)}')\n",
    "\n",
    "pd.DataFrame({'feat_importance': model.feature_importances_}, index = X_train.columns).\\\n",
    "sort_values(by = 'feat_importance', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Задание 4\n",
    "\n",
    "\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Columns: 31 entries, Time to Class\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "print(df.Class.value_counts(normalize=True), '\\n')\n",
    "\n",
    "# Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.\n",
    "df.info(verbose=False)\n",
    "\n",
    "# Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма: pd.options.display.max_columns = 100.\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# Просмотрите первые 10 строк датафрейма df.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df (284807, 31)\n",
      "X_train (199364, 30), X_test (85443, 30)\n",
      "y_train (199364,), y_test (85443,)\n"
     ]
    }
   ],
   "source": [
    "# Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "X = df.drop(['Class'], axis='columns')\n",
    "\n",
    "# Создайте объект Series под названием y из столбца Class.\n",
    "y = df.Class\n",
    "\n",
    "# Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: \n",
    "# test_size=0.3, random_state=100, stratify=y. У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 100, stratify=y)\n",
    "\n",
    "# Просмотрите информацию о их форме.\n",
    "print(f'df {df.shape}\\nX_train {X_train.shape}, X_test {X_test.shape}\\ny_train {y_train.shape}, y_test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': array([4, 5, 6]),\n",
       "                         'max_features': array([3, 4]),\n",
       "                         'n_estimators': [10, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Для поиска по сетке параметров задайте такие параметры:\n",
    "#parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "parameters = {'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}\n",
    "\n",
    "#Создайте модель GridSearchCV со следующими аргументами:\n",
    "#estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3.\n",
    "\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3)\n",
    "\n",
    "# Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'max_depth': 6, 'max_features': 3, 'n_estimators': 15}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00092917, 0.00029521, 0.00028215, ..., 0.00028215, 0.0006822 ,\n",
       "       0.01246098])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "\n",
    "print(f'best_params_: {clf.best_params_}')\n",
    "\n",
    "#Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "# Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) \n",
    "# и запишите в массив y_pred_proba. \n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462664156037156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "# Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, \n",
    "# используя в качестве аргументов массивы y_test и y_pred_proba.\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Дополнительные задания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data\n",
    "\n",
    "data = load_wine()\n",
    "\n",
    "# 2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. \n",
    "#     Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи.\n",
    "\n",
    "print(type(data))\n",
    "data_keys = data.keys()\n",
    "data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные:\n",
      " [[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]] \n",
      "\n",
      "Описание:\n",
      " .. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      " \n",
      "\n",
      "Названия признаков:\n",
      " ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "# 3). Просмотрите данные, описание и названия признаков в датасете. \n",
    "#     Описание нужно вывести в виде привычного, аккуратно оформленного текста, \n",
    "#     без обозначений переноса строки, но с самими переносами и т.д.\n",
    "\n",
    "print('Данные:\\n', data.data,\n",
    "      '\\n\\nОписание:\\n', data.DESCR, \n",
    "      '\\n\\nНазвания признаков:\\n', data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во классов: 3\n",
      "Имена: ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# 4). Сколько классов содержит целевая переменная датасета? Выведите названия классов.\n",
    "\n",
    "print(f'Кол-во классов: {len(data.target_names)}\\nИмена: {data.target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и \n",
    "#     названий признаков создайте датафрейм под названием X.\n",
    "\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      "alcohol                         178 non-null float64\n",
      "malic_acid                      178 non-null float64\n",
      "ash                             178 non-null float64\n",
      "alcalinity_of_ash               178 non-null float64\n",
      "magnesium                       178 non-null float64\n",
      "total_phenols                   178 non-null float64\n",
      "flavanoids                      178 non-null float64\n",
      "nonflavanoid_phenols            178 non-null float64\n",
      "proanthocyanins                 178 non-null float64\n",
      "color_intensity                 178 non-null float64\n",
      "hue                             178 non-null float64\n",
      "od280/od315_of_diluted_wines    178 non-null float64\n",
      "proline                         178 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n"
     ]
    }
   ],
   "source": [
    "# 6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 1 columns):\n",
      "target    178 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.5 KB\n"
     ]
    }
   ],
   "source": [
    "# 7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. \n",
    "#     Название поля - 'target'.\n",
    "\n",
    "X['target'] = data.target.astype(np.int64)\n",
    "X[['target']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.\n",
    "\n",
    "X_corr = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcalinity_of_ash']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному \n",
    "# значению превышает 0.5 (причем, само поле target не должно входить в этот список).\n",
    "\n",
    "high_corr = list(X_corr[(X_corr.target > 0.5) & (X_corr.target < 1)].index)\n",
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>alcalinity_of_ash_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>391.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>133.671775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>112.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>295.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>380.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>462.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "       alcalinity_of_ash_2  \n",
       "count           178.000000  \n",
       "mean            391.142865  \n",
       "std             133.671775  \n",
       "min             112.360000  \n",
       "25%             295.840000  \n",
       "50%             380.250000  \n",
       "75%             462.250000  \n",
       "max             900.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10). Удалите из датафрейма X поле с целевой переменной. \n",
    "X.drop(['target'], axis='columns', inplace = True)\n",
    "\n",
    "# Для всех признаков, названия которых содержатся в списке high_corr, \n",
    "# вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', \n",
    "# добавленного к первоначальному названию признака. \n",
    "\n",
    "for i in high_corr:\n",
    "    X[i + '_2'] = X[i]**2\n",
    "\n",
    "# Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, \n",
    "# а также поля с признаками из списка high_corr, возведенными в квадрат. \n",
    "# Выведите описание полей датафрейма X с помощью метода describe.\n",
    "\n",
    "X.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
